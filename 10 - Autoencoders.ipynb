{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Autoencoders\n",
                "\n",
                "Neste notebook, exploraremos os **Autoencoders**, uma classe fundamental de redes neurais utilizadas no aprendizado não supervisionado. O principal objetivo de um autoencoder é aprender uma representação eficiente (encoding) para um conjunto de dados, tipicamente para redução de dimensionalidade.\n",
                "\n",
                "Aprenderemos:\n",
                "1.  O que são Autoencoders e como funcionam.\n",
                "2.  Conceitos básicos de Redes Neurais e Keras.\n",
                "3.  Como implementar um Autoencoder Simples para reconstruir imagens.\n",
                "4.  Como implementar um Denoising Autoencoder para remover ruído de imagens.\n",
                "5.  Como visualizar o espaço latente aprendido."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Fundamentos Matemáticos e Teóricos\n",
                "\n",
                "### O que é um Autoencoder?\n",
                "\n",
                "Um autoencoder é uma rede neural projetada para reproduzir sua entrada na saída. Internamente, ele possui uma camada oculta que descreve um código usado para representar a entrada. A rede pode ser vista como consistindo de duas partes principais:\n",
                "\n",
                "1.  **Encoder (Codificador)**: Uma função $f$ que comprime a entrada $x$ em uma representação latente $z$. $$z = f(x)$$\n",
                "2.  **Decoder (Decodificador)**: Uma função $g$ que reconstrói a entrada $\\hat{x}$ a partir da representação latente $z$. $$\\hat{x} = g(z)$$\n",
                "\n",
                "Se o autoencoder for capaz de aprender $g(f(x)) = x$ perfeitamente em todos os lugares, ele não é muito útil. Em vez disso, autoencoders são projetados para não serem capazes de copiar perfeitamente. O objetivo é restringir o modelo de forma que ele só consiga copiar aproximadamente, forçando-o a priorizar quais aspectos da entrada devem ser copiados. Isso geralmente é feito limitando a dimensão de $z$ (o gargalo ou *bottleneck*).\n",
                "\n",
                "### Objetivo\n",
                "\n",
                "O treinamento consiste em minimizar uma função de perda $L$, que mede a diferença entre a entrada original $x$ e a reconstrução $\\hat{x}$. Uma escolha comum é o Erro Quadrático Médio (MSE):\n",
                "\n",
                "$$ L(x, \\hat{x}) = ||x - \\hat{x}||^2 $$\n",
                "\n",
                "### Breve Revisão de Redes Neurais\n",
                "\n",
                "Para implementar nosso autoencoder, usaremos redes neurais densas (Fully Connected).\n",
                "\n",
                "-   **Neurônio**: A unidade básica, que recebe entradas, aplica pesos ($W$), um viés ($b$) e uma função de ativação. A saída é $y = \\text{ativação}(W \\cdot x + b)$.\n",
                "-   **Camadas**: Neurônios são organizados em camadas. Em uma camada densa, cada neurônio está conectado a todos os neurônios da camada anterior.\n",
                "-   **Funções de Ativação**: Introduzem não-linearidade. Usaremos `ReLU` (Rectified Linear Unit) nas camadas ocultas e `Sigmoid` na saída (para escalar os pixels entre 0 e 1)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Implementação com Keras e MNIST\n",
                "\n",
                "### Biblioteca: Keras\n",
                "\n",
                "O **Keras** é uma API de alto nível para redes neurais, escrita em Python e capaz de rodar sobre o TensorFlow. Ele foi desenvolvido com foco em facilitar a experimentação rápida.\n",
                "\n",
                "Conceitos chave do Keras que usaremos:\n",
                "-   **Input**: Define a forma da entrada.\n",
                "-   **Dense**: Camada de rede neural densamente conectada.\n",
                "-   **Model**: Agrupa camadas em um objeto com métodos de treinamento e inferência (`model.compile`, `model.fit`).\n",
                "\n",
                "### Dataset: MNIST\n",
                "\n",
                "Usaremos o dataset **MNIST**, que consiste em 70.000 imagens em tons de cinza de dígitos manuscritos (0-9), com dimensão 28x28 pixels."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'tensorflow'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mnist\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Dense\n",
                        "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from tensorflow.keras.datasets import mnist\n",
                "from tensorflow.keras.models import Model\n",
                "from tensorflow.keras.layers import Input, Dense"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Carregar os dados (vamos usar apenas as imagens, pois é não supervisionado)\n",
                "(x_train, _), (x_test, _) = mnist.load_data()\n",
                "\n",
                "# Normalizar os dados para o intervalo [0, 1]\n",
                "x_train = x_train.astype('float32') / 255.\n",
                "x_test = x_test.astype('float32') / 255.\n",
                "\n",
                "# Redimensionar as imagens de (28, 28) para vetores de tamanho 784\n",
                "# Isso é necessário porque usaremos camadas Densas, que esperam vetores flat\n",
                "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
                "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
                "\n",
                "print(\"Shape de treino:\", x_train.shape)\n",
                "print(\"Shape de teste:\", x_test.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualizar algumas amostras do dataset\n",
                "n = 10  # Quantas imagens mostrar\n",
                "plt.figure(figsize=(20, 2))\n",
                "for i in range(n):\n",
                "    ax = plt.subplot(1, n, i + 1)\n",
                "    plt.imshow(x_train[i].reshape(28, 28))\n",
                "    plt.gray()\n",
                "    ax.get_xaxis().set_visible(False)\n",
                "    ax.get_yaxis().set_visible(False)\n",
                "plt.suptitle(\"Amostras do MNIST\", fontsize=16)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Autoencoder Simples\n",
                "\n",
                "Vamos criar um autoencoder básico com uma única camada oculta. A dimensão de entrada é 784 (28x28) e a dimensão latente (encoding) será 32. Isso significa um fator de compressão de 24.5x."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dimensão da representação codificada\n",
                "encoding_dim = 32\n",
                "\n",
                "# 1. Input Placeholder\n",
                "input_img = Input(shape=(784,))\n",
                "\n",
                "# 2. Camada Encoder (codificada)\n",
                "# \"encoded\" é a representação comprimida da entrada\n",
                "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
                "\n",
                "# 3. Camada Decoder (decodificada)\n",
                "# \"decoded\" é a reconstrução da entrada (com perda)\n",
                "decoded = Dense(784, activation='sigmoid')(encoded)\n",
                "\n",
                "# 4. Modelo Autoencoder (Mapeia input -> reconstrução)\n",
                "autoencoder = Model(input_img, decoded)\n",
                "\n",
                "# Vamos criar também um modelo separado para o encoder (para usarmos depois)\n",
                "encoder = Model(input_img, encoded)\n",
                "\n",
                "# Resumo da arquitetura\n",
                "autoencoder.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Treinamento\n",
                "\n",
                "Configuramos o modelo para minimizar a perda `binary_crossentropy` (comumente usada quando os pixels estão entre 0 e 1, interpretados como probabilidades) usando o otimizador `adam`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
                "\n",
                "# Treinamos o modelo por 50 épocas\n",
                "# Note que x_train é usado tanto como entrada quanto como alvo (x -> x)\n",
                "history = autoencoder.fit(x_train, x_train,\n",
                "                epochs=50,\n",
                "                batch_size=256,\n",
                "                shuffle=True,\n",
                "                validation_data=(x_test, x_test),\n",
                "                verbose=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualização dos Resultados\n",
                "\n",
                "Vamos comparar as imagens originais com as reconstruções feitas pelo autoencoder."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Codificar e decodificar algumas imagens do conjunto de teste\n",
                "encoded_imgs = encoder.predict(x_test)\n",
                "decoded_imgs = autoencoder.predict(x_test)\n",
                "\n",
                "n = 10  # Quantas imagens mostrar\n",
                "plt.figure(figsize=(20, 4))\n",
                "for i in range(n):\n",
                "    # Exibir original\n",
                "    ax = plt.subplot(2, n, i + 1)\n",
                "    plt.imshow(x_test[i].reshape(28, 28))\n",
                "    plt.gray()\n",
                "    ax.get_xaxis().set_visible(False)\n",
                "    ax.get_yaxis().set_visible(False)\n",
                "    if i == n // 2:\n",
                "        ax.set_title(\"Originais\")\n",
                "\n",
                "    # Exibir reconstrução\n",
                "    ax = plt.subplot(2, n, i + 1 + n)\n",
                "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
                "    plt.gray()\n",
                "    ax.get_xaxis().set_visible(False)\n",
                "    ax.get_yaxis().set_visible(False)\n",
                "    if i == n // 2:\n",
                "        ax.set_title(\"Reconstruções\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualização do Espaço Latente com t-SNE\n",
                "\n",
                "O \"código\" aprendido pelo encoder tem dimensão 32. Podemos usar o t-SNE (visto em notebooks anteriores) para visualizar como os dígitos estão organizados nesse espaço latente."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.manifold import TSNE\n",
                "\n",
                "# Usar uma amostra para o t-SNE (para ser mais rápido)\n",
                "n_samples = 1000\n",
                "x_test_subset = x_test[:n_samples]\n",
                "encoded_subset = encoded_imgs[:n_samples]\n",
                "\n",
                "# Obter os labels (apenas para colorir o gráfico)\n",
                "_, (y_test_labels, _) = mnist.load_data()\n",
                "y_test_subset = y_test_labels[:n_samples]\n",
                "\n",
                "tsne = TSNE(n_components=2, random_state=42)\n",
                "tsne_results = tsne.fit_transform(encoded_subset)\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "scatter = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=y_test_subset, cmap='tab10', alpha=0.6)\n",
                "plt.colorbar(scatter, ticks=range(10))\n",
                "plt.title('t-SNE do Espaço Latente (32D -> 2D)')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Denoising Autoencoder\n",
                "\n",
                "Um Denoising Autoencoder (DAE) é treinado para reconstruir uma entrada limpa a partir de uma versão corrompida (ruidosa) dela. Isso força o modelo a aprender características robustas e a ignorar o ruído.\n",
                "\n",
                "### Adicionando Ruído\n",
                "\n",
                "Vamos adicionar ruído gaussiano às imagens do MNIST."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "noise_factor = 0.5\n",
                "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
                "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
                "\n",
                "# Clipar os valores para ficar entre 0 e 1\n",
                "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
                "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
                "\n",
                "# Visualizar imagens ruidosas\n",
                "n = 10\n",
                "plt.figure(figsize=(20, 2))\n",
                "for i in range(n):\n",
                "    ax = plt.subplot(1, n, i + 1)\n",
                "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
                "    plt.gray()\n",
                "    ax.get_xaxis().set_visible(False)\n",
                "    ax.get_yaxis().set_visible(False)\n",
                "plt.suptitle(\"Entrada Ruidosa\", fontsize=16)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Modelo DAE\n",
                "\n",
                "Usaremos uma arquitetura um pouco mais profunda (Deep Autoencoder) para melhor capacidade."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "input_img = Input(shape=(784,))\n",
                "\n",
                "# Encoder mais profundo\n",
                "x = Dense(128, activation='relu')(input_img)\n",
                "x = Dense(64, activation='relu')(x)\n",
                "encoded = Dense(32, activation='relu')(x)\n",
                "\n",
                "# Decoder correspondente\n",
                "x = Dense(64, activation='relu')(encoded)\n",
                "x = Dense(128, activation='relu')(x)\n",
                "decoded = Dense(784, activation='sigmoid')(x)\n",
                "\n",
                "dae = Model(input_img, decoded)\n",
                "dae.compile(optimizer='adam', loss='binary_crossentropy')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# O treino agora usa x_train_noisy como entrada, mas x_train (limpo) como alvo\n",
                "dae.fit(x_train_noisy, x_train,\n",
                "        epochs=50,\n",
                "        batch_size=128,\n",
                "        shuffle=True,\n",
                "        validation_data=(x_test_noisy, x_test),\n",
                "        verbose=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Resultados do Denoising\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "decoded_imgs = dae.predict(x_test_noisy)\n",
                "\n",
                "n = 10\n",
                "plt.figure(figsize=(20, 6))\n",
                "for i in range(n):\n",
                "    # Ruidoso\n",
                "    ax = plt.subplot(3, n, i + 1)\n",
                "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
                "    plt.gray()\n",
                "    ax.get_xaxis().set_visible(False)\n",
                "    ax.get_yaxis().set_visible(False)\n",
                "    if i == n // 2: ax.set_title(\"Ruidoso\")\n",
                "\n",
                "    # Reconstruído\n",
                "    ax = plt.subplot(3, n, i + 1 + n)\n",
                "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
                "    plt.gray()\n",
                "    ax.get_xaxis().set_visible(False)\n",
                "    ax.get_yaxis().set_visible(False)\n",
                "    if i == n // 2: ax.set_title(\"Reconstruído (Limpo)\")\n",
                "\n",
                "    # Original (Ground Truth)\n",
                "    ax = plt.subplot(3, n, i + 1 + 2*n)\n",
                "    plt.imshow(x_test[i].reshape(28, 28))\n",
                "    plt.gray()\n",
                "    ax.get_xaxis().set_visible(False)\n",
                "    ax.get_yaxis().set_visible(False)\n",
                "    if i == n // 2: ax.set_title(\"Original\")\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Exercícios\n",
                "\n",
                "Use as células abaixo para experimentar:\n",
                "\n",
                "1.  **Impacto do Bottleneck**: Altere o `encoding_dim` no Autoencoder Simples para um valor muito pequeno (ex: 4 ou 2) e observe a qualidade da reconstrução. O que acontece com os dígitos? Eles ficam borrados? Ainda são reconhecíveis?\n",
                "2.  **Deep Autoencoder Simples**: O Autoencoder Simples usou apenas uma camada oculta. Tente adicionar mais camadas (como fizemos no Denoising AE) mas para a tarefa de reconstrução simples (sem ruído). Compare a perda final (loss) e a nitidez das imagens com o modelo de camada única."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercício 1: Seu código aqui\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercício 2: Seu código aqui\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
