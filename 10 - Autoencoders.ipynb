{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Autoencoders\n",
                "\n",
                "Neste notebook, exploraremos os **Autoencoders**, uma classe fundamental de redes neurais utilizadas no aprendizado não supervisionado. O principal objetivo de um autoencoder é aprender uma representação eficiente (encoding) para um conjunto de dados, tipicamente para redução de dimensionalidade."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Fundamentos\n",
                "\n",
                "### O que é um Autoencoder?\n",
                "\n",
                "Um autoencoder é uma rede neural projetada para reproduzir sua entrada na saída. Internamente, ele possui uma camada oculta que descreve um código usado para representar a entrada. A rede pode ser vista como consistindo de duas partes principais:\n",
                "\n",
                "1.  **Encoder (Codificador)**: Uma função $f$ que comprime a entrada $x$ em uma representação latente $z$. $$z = f(x)$$\n",
                "2.  **Decoder (Decodificador)**: Uma função $g$ que reconstrói a entrada $\\hat{x}$ a partir da representação latente $z$. $$\\hat{x} = g(z)$$\n",
                "\n",
                "Se o autoencoder for capaz de aprender $g(f(x)) = x$ perfeitamente em todos os lugares, ele não é muito útil. Em vez disso, autoencoders são projetados para não serem capazes de copiar perfeitamente. O objetivo é restringir o modelo de forma que ele só consiga copiar aproximadamente, forçando-o a priorizar quais aspectos da entrada devem ser copiados. Isso geralmente é feito limitando a dimensão de $z$ (o gargalo ou *bottleneck*).\n",
                "\n",
                "### Objetivo\n",
                "\n",
                "O treinamento consiste em minimizar uma função de perda $L$, que mede a diferença entre a entrada original $x$ e a reconstrução $\\hat{x}$. Uma escolha comum é o Erro Quadrático Médio (MSE):\n",
                "\n",
                "$$ L(x, \\hat{x}) = ||x - \\hat{x}||^2 $$\n",
                "\n",
                "### Breve Revisão de Redes Neurais\n",
                "\n",
                "Para implementar nosso autoencoder, usaremos redes neurais densas (Fully Connected).\n",
                "\n",
                "-   **Neurônio**: A unidade básica, que recebe entradas, aplica pesos ($W$), um viés ($b$) e uma função de ativação. A saída é $y = \\text{ativação}(W \\cdot x + b)$.\n",
                "-   **Camadas**: Neurônios são organizados em camadas. Em uma camada densa, cada neurônio está conectado a todos os neurônios da camada anterior.\n",
                "-   **Funções de Ativação**: Introduzem não-linearidade. Usaremos `ReLU` (Rectified Linear Unit) nas camadas ocultas e `Sigmoid` na saída (para escalar os pixels entre 0 e 1)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Implementação com Keras e MNIST\n",
                "\n",
                "### Biblioteca: Keras\n",
                "\n",
                "O **Keras** é uma API de alto nível para redes neurais, escrita em Python e capaz de rodar sobre o TensorFlow. Ele foi desenvolvido com foco em facilitar a experimentação rápida.\n",
                "\n",
                "Conceitos chave do Keras que usaremos:\n",
                "-   **Input**: Define a forma da entrada.\n",
                "-   **Dense**: Camada de rede neural densamente conectada.\n",
                "-   **Model**: Agrupa camadas em um objeto com métodos de treinamento e inferência (`model.compile`, `model.fit`).\n",
                "\n",
                "### Dataset: MNIST\n",
                "\n",
                "Usaremos o dataset **MNIST**, que consiste em 70.000 imagens em tons de cinza de dígitos manuscritos (0-9), com dimensão 28x28 pixels."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from tensorflow.keras.datasets import mnist\n",
                "from tensorflow.keras.models import Model\n",
                "from tensorflow.keras.layers import Input, Dense"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Carregar os dados (vamos usar apenas as imagens, pois é não supervisionado)\n",
                "(x_train, _), (x_test, _) = mnist.load_data()\n",
                "\n",
                "# Normalizar os dados para o intervalo [0, 1]\n",
                "x_train = x_train.astype('float32') / 255.\n",
                "x_test = x_test.astype('float32') / 255.\n",
                "\n",
                "# Redimensionar as imagens de (28, 28) para vetores de tamanho 784\n",
                "# Isso é necessário porque usaremos camadas Densas, que esperam vetores flat\n",
                "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
                "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
                "\n",
                "print(\"Shape de treino:\", x_train.shape)\n",
                "print(\"Shape de teste:\", x_test.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualizar algumas amostras do dataset\n",
                "n = 10  # Quantas imagens mostrar\n",
                "plt.figure(figsize=(20, 2))\n",
                "for i in range(n):\n",
                "    ax = plt.subplot(1, n, i + 1)\n",
                "    plt.imshow(x_train[i].reshape(28, 28))\n",
                "    plt.gray()\n",
                "    ax.get_xaxis().set_visible(False)\n",
                "    ax.get_yaxis().set_visible(False)\n",
                "plt.suptitle(\"Amostras do MNIST\", fontsize=16)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Autoencoder Simples\n",
                "\n",
                "Vamos criar um autoencoder básico com uma única camada oculta. A dimensão de entrada é 784 (28x28) e a dimensão latente (encoding) será 32. Isso significa um fator de compressão de 24.5x."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dimensão da representação codificada\n",
                "encoding_dim = 32"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Input Placeholder\n",
                "input_img = Input(shape=(784,))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Camada Encoder\n",
                "encoded = Dense(128, activation='relu')(input_img)\n",
                "encoded = Dense(encoding_dim, activation='relu', name=\"latent\")(encoded)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Camada Decoder\n",
                "decoded = Dense(128, activation='relu')(encoded)\n",
                "decoded = Dense(784, activation='sigmoid')(decoded)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Modelo Autoencoder\n",
                "autoencoder = Model(input_img, decoded)\n",
                "\n",
                "# Modelo separado para o encoder\n",
                "encoder = Model(input_img, encoded)\n",
                "\n",
                "# Modelo separado para o decoder\n",
                "encoded_input = Input(shape=(encoding_dim,))\n",
                "decoder_layer = autoencoder.layers[-2](encoded_input)\n",
                "decoder_layer = autoencoder.layers[-1](decoder_layer)\n",
                "decoder = Model(encoded_input, decoder_layer)\n",
                "\n",
                "# Resumo da arquitetura\n",
                "autoencoder.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Treinamento\n",
                "\n",
                "Configuramos o modelo para minimizar a perda `binary_crossentropy` (comumente usada quando os pixels estão entre 0 e 1, interpretados como probabilidades) usando o otimizador `adam`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "autoencoder.compile(optimizer='adam', loss='mse')\n",
                "\n",
                "# Treinamos o modelo por 20 épocas\n",
                "# Note que x_train é usado tanto como entrada quanto como alvo (x -> x)\n",
                "history = autoencoder.fit(x_train, x_train,\n",
                "                epochs=20,\n",
                "                batch_size=256,\n",
                "                shuffle=True,\n",
                "                validation_data=(x_test, x_test),\n",
                "                verbose=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(history.history['loss'], label='loss')\n",
                "plt.plot(history.history['val_loss'], label='val_loss')\n",
                "plt.xlabel('Época')\n",
                "plt.ylabel('Loss')\n",
                "plt.legend()\n",
                "plt.title('Loss durante o treinamento')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualização dos Resultados\n",
                "\n",
                "Vamos comparar as imagens originais com as reconstruções feitas pelo autoencoder."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "encoded_imgs = encoder.predict(x_test)\n",
                "decoded_imgs = autoencoder.predict(x_test)\n",
                "\n",
                "n = 10\n",
                "plt.figure(figsize=(20, 4))\n",
                "for i in range(n):\n",
                "    # Exibir original\n",
                "    ax = plt.subplot(2, n, i + 1)\n",
                "    plt.imshow(x_test[i].reshape(28, 28))\n",
                "    plt.gray()\n",
                "    ax.get_xaxis().set_visible(False)\n",
                "    ax.get_yaxis().set_visible(False)\n",
                "    if i == n // 2:\n",
                "        ax.set_title(\"Originais\")\n",
                "\n",
                "    # Exibir reconstrução\n",
                "    ax = plt.subplot(2, n, i + 1 + n)\n",
                "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
                "    plt.gray()\n",
                "    ax.get_xaxis().set_visible(False)\n",
                "    ax.get_yaxis().set_visible(False)\n",
                "    if i == n // 2:\n",
                "        ax.set_title(\"Reconstruções\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualização do Espaço Latente com t-SNE\n",
                "\n",
                "O \"código\" aprendido pelo encoder tem dimensão 32. Podemos usar o t-SNE (visto em notebooks anteriores) para visualizar como os dígitos estão organizados nesse espaço latente."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.manifold import TSNE\n",
                "\n",
                "n_samples = 1000\n",
                "encoded_subset = np.asarray(encoded_imgs[:n_samples])\n",
                "\n",
                "(_, _), (_, y_test) = mnist.load_data()\n",
                "y_test_subset = y_test[:n_samples].astype(int)\n",
                "\n",
                "tsne = TSNE(n_components=2, random_state=42, init=\"pca\", learning_rate=\"auto\")\n",
                "tsne_results = tsne.fit_transform(encoded_subset)\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "sc = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=y_test_subset, cmap=\"tab10\", s=12, alpha=0.7)\n",
                "plt.colorbar(sc, ticks=range(10))\n",
                "plt.title(\"t-SNE do Espaço Latente (32D -> 2D)\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Denoising Autoencoder\n",
                "\n",
                "Um Denoising Autoencoder (DAE) é treinado para reconstruir uma entrada limpa a partir de uma versão corrompida (ruidosa) dela. Isso força o modelo a aprender características robustas e a ignorar o ruído.\n",
                "\n",
                "### Adicionando Ruído\n",
                "\n",
                "Vamos adicionar ruído gaussiano às imagens do MNIST."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "noise_factor = 0.5\n",
                "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
                "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
                "\n",
                "# Clipar os valores para ficar entre 0 e 1\n",
                "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
                "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
                "\n",
                "# Visualizar imagens ruidosas\n",
                "n = 10\n",
                "plt.figure(figsize=(20, 2))\n",
                "for i in range(n):\n",
                "    ax = plt.subplot(1, n, i + 1)\n",
                "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
                "    plt.gray()\n",
                "    ax.get_xaxis().set_visible(False)\n",
                "    ax.get_yaxis().set_visible(False)\n",
                "plt.suptitle(\"Entrada Ruidosa\", fontsize=16)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Modelo DAE\n",
                "\n",
                "Usaremos uma arquitetura profunda (Deep Autoencoder) para melhor capacidade."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "input_img = Input(shape=(784,))\n",
                "\n",
                "# Encoder\n",
                "x = Dense(128, activation='relu')(input_img)\n",
                "x = Dense(64, activation='relu')(x)\n",
                "encoded = Dense(32, activation='relu')(x)\n",
                "\n",
                "# Decoder\n",
                "x = Dense(64, activation='relu')(encoded)\n",
                "x = Dense(128, activation='relu')(x)\n",
                "decoded = Dense(784, activation='sigmoid')(x)\n",
                "\n",
                "dae = Model(input_img, decoded)\n",
                "dae.compile(optimizer='adam', loss='mse')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# O treino agora usa x_train_noisy como entrada, mas x_train (limpo) como alvo\n",
                "dae.fit(x_train_noisy, x_train,\n",
                "        epochs=20,\n",
                "        batch_size=128,\n",
                "        shuffle=True,\n",
                "        validation_data=(x_test_noisy, x_test),\n",
                "        verbose=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Resultados do Denoising\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "decoded_imgs = dae.predict(x_test_noisy)\n",
                "\n",
                "n = 10\n",
                "plt.figure(figsize=(20, 6))\n",
                "for i in range(n):\n",
                "    # Ruidoso\n",
                "    ax = plt.subplot(3, n, i + 1)\n",
                "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
                "    plt.gray()\n",
                "    ax.get_xaxis().set_visible(False)\n",
                "    ax.get_yaxis().set_visible(False)\n",
                "    if i == n // 2: ax.set_title(\"Ruidoso\")\n",
                "\n",
                "    # Reconstruído\n",
                "    ax = plt.subplot(3, n, i + 1 + n)\n",
                "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
                "    plt.gray()\n",
                "    ax.get_xaxis().set_visible(False)\n",
                "    ax.get_yaxis().set_visible(False)\n",
                "    if i == n // 2: ax.set_title(\"Reconstruído (Limpo)\")\n",
                "\n",
                "    # Original (Ground Truth)\n",
                "    ax = plt.subplot(3, n, i + 1 + 2*n)\n",
                "    plt.imshow(x_test[i].reshape(28, 28))\n",
                "    plt.gray()\n",
                "    ax.get_xaxis().set_visible(False)\n",
                "    ax.get_yaxis().set_visible(False)\n",
                "    if i == n // 2: ax.set_title(\"Original\")\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Exercícios"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercício 1\n",
                "\n",
                "Altere o `encoding_dim` no Autoencoder Simples para um valor muito pequeno (ex: 4 ou 2) e observe a qualidade da reconstrução. O que acontece com os dígitos? Eles ficam borrados? Ainda são reconhecíveis?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercício 1: Seu código aqui\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercício 2\n",
                "\n",
                "O Autoencoder Simples usou apenas uma camada oculta. Tente adicionar mais camadas (como fizemos no Denoising AE) mas para a tarefa de reconstrução simples (sem ruído). Compare a perda final (loss) e a nitidez das imagens com o modelo de camada única."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercício 2: Seu código aqui\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
